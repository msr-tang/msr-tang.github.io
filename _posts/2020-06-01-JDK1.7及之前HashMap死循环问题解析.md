---
layout:     post                    # 使用的布局（不需要改）
title:      JDK1.7及之前HashMap死循环问题解析   # 标题 
subtitle:   HashMap线程不安全 					#副标题
date:       2020-06-01              # 时间
author:     BY tang                     # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - java
---

# JDK 1.7及之前——HashMap死循环问题解析 #
[上篇文章](http://zytblog.top/2020/06/01/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8cpu%E7%88%86%E6%BB%A1%E6%8E%92%E6%9F%A5/)说了一个CPU被100%的线上故障，并且这个事发生了很多次，原因是在Java语言在并发情况下使用HashMap造成Race Condition，从而导致死循环。因为Java的HashMap是非线程安全的，所以在并发下必然出现问题。
> 文章参考：[https://blog.csdn.net/pange1991/article/details/82377980](https://blog.csdn.net/pange1991/article/details/82377980)

从前我们的Java代码因为一些原因使用了HashMap这个东西，但是当时的程序是单线程的，一切都没有问题。后来，我们的程序性能有问题，所以需要变成多线程的，于是，变成多线程后到了线上，发现程序经常占了100%的CPU，查看堆栈，你会发现程序都Hang在了HashMap.get()这个方法上了，重启程序后问题消失。但是过段时间又会来。而且，这个问题在测试环境里可能很难重现。Java的文档说HashMap是非线程安全的，应该用ConcurrentHashMap。

## Hash表数据结构 ##

HashMap通常会用一个指针数组（假设为table[]）来做分散所有的key，当一个key被加入时，会通过Hash算法通过key算出这个数组的下标i，然后就把这个<key, value>插到table[i]中，如果有两个不同的key被算在了同一个i，那么就叫冲突，又叫碰撞，这样会在table[i]上形成一个链表。

我们知道，如果table[]的尺寸很小，比如只有2个，如果要放进10个keys的话，那么碰撞非常频繁，于是一个O(1)的查找算法，就变成了链表遍历，性能变成了O(n)，这是Hash表的缺陷。

所以，Hash表的尺寸和容量非常的重要。一般来说，Hash表这个容器当有数据要插入时，都会检查容量有没有超过设定的thredhold，如果超过，需要增大Hash表的尺寸，但是这样一来，整个Hash表里的无素都需要被重算一遍。这叫rehash，这个成本相当的大。

## HashMap的rehash源代码 ##
Put一个Key,Value对到Hash表中：

	public V put(K key, V value){
	    ......
	    //算Hash值
	    int hash = hash(key.hashCode());
	    int i = indexFor(hash, table.length);
	    //如果该key已被插入，则替换掉旧的value （链接操作）
	    for (Entry<K,V> e = table[i]; e != null; e = e.next) {
	        Object k;
	        if (e.hash == hash && ((k = e.key) == key || key.equals(k))) {
	            V oldValue = e.value;
	            e.value = value;
	            e.recordAccess(this);
	            return oldValue;
	        }
	    }
	    modCount++;
	    //该key不存在，需要增加一个结点
	    addEntry(hash, key, value, i);
	    return null;
	}
检查容量是否超标:

	void addEntry(int hash, K key, V value, int bucketIndex){
	    Entry<K,V> e = table[bucketIndex];
	    table[bucketIndex] = new Entry<K,V>(hash, key, value, e);
	    //查看当前的size是否超过了我们设定的阈值threshold，如果超过，需要resize
	    if (size++ >= threshold)
	        resize(2 * table.length);
	}

新建一个更大尺寸的hash表，然后把数据从老的Hash表中迁移到新的Hash表中:

	void resize(int newCapacity){
	    Entry[] oldTable = table;
	    int oldCapacity = oldTable.length;
	    ......
	    //创建一个新的Hash Table
	    Entry[] newTable = new Entry[newCapacity];
	    //将Old Hash Table上的数据迁移到New Hash Table上
	    transfer(newTable);
	    table = newTable;
	    threshold = (int)(newCapacity * loadFactor);
	}

迁移的源代码：

	void transfer(Entry[] newTable){
	    Entry[] src = table;
	    int newCapacity = newTable.length;
	    //下面这段代码的意思是：
	    //从OldTable里摘一个元素出来，然后放到NewTable中
	    for (int j = 0; j < src.length; j++) {
	        Entry<K,V> e = src[j];
	        if (e != null) {
	            src[j] = null;
	            do {
	                Entry<K,V> next = e.next;
	                int i = indexFor(e.hash, newCapacity);
	                e.next = newTable[i];
	                newTable[i] = e;
	                e = next;
	            } while (e != null);
	        }
	    }
	}

----------

### 正常的ReHash的过程 ###

画了个图做了个演示。

- 我假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）。
- 最上面的是old hash 表，其中的Hash表的size=2, 所以key = 3, 7, 5，在mod 2以后都冲突在table[1]这里了。
- 接下来的三个步骤是Hash表 resize成4，然后所有的<key,value> 重新rehash的过程
![](https://i.niupic.com/images/2020/06/07/8eX2.jpg)
----------

### 并发下的Rehash ###
1）**假设我们有两个线程。**我用红色和浅蓝色标注了一下。

我们再回头看一下我们的 transfer代码中的这个细节：

	do {
	    Entry<K,V> next = e.next; // <--假设线程一执行到这里就被调度挂起了
	    int i = indexFor(e.hash, newCapacity);
	    e.next = newTable[i];
	    newTable[i] = e;
	    e = next;
	} while (e != null);

而我们的线程二执行完成了。于是我们有下面的这个样子:
![](https://i.niupic.com/images/2020/06/07/8eX0.jpg)

注意，**因为Thread1的 e 指向了key(3)，而next指向了key(7)，其在线程二rehash后，指向了线程二重组后的链表。**我们可以看到链表的顺序被反转后。

2）**线程一被调度回来执行。**

- **先是执行 newTalbe[i] = e;**
- **然后是e = next，导致了e指向了key(7)，**
- **而下一次循环的next = e.next导致了next指向了key(3)**
![](https://i.niupic.com/images/2020/06/07/8eX5.jpg)

3）**一切安好。**

线程一接着工作。**把key(7)摘下来，放到newTable[i]的第一个，然后把e和next往下移。**
![](https://i.niupic.com/images/2020/06/07/8eX7.jpg)

4）**环形链接出现。**

**e.next = newTable[i] 导致  key(3).next 指向了 key(7)**

**注意：此时的key(7).next 已经指向了key(3)， 环形链表就这样出现了。**
![](https://i.niupic.com/images/2020/06/07/8eX1.jpg)

**于是，当我们的线程一调用到，HashTable.get(11)时，悲剧就出现了——Infinite Loop。**


----------
解决方案：

- 涉及到多线程的地方，改用ConcurrentHashMap，HashSet的底层其实用的也是HasMap实现的，可以转化为ConcurrentHashMap<key,1>,就是把ConcurrentHashMap中的value值固定。
- 对于已经上线的项目，可能用到HasMap/HashSet的地方非常多，可以升级到jdk1.8（存在数据丢失的问题）















